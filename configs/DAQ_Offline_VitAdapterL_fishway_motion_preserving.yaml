_BASE_: ../DVIS_Plus/DVIS_DAQ/configs/dvis_daq/ytvis21/vit_adapter/DAQ_Offline_VitAdapterL.yaml  # file to inherit settings from

MODEL:
  META_ARCHITECTURE: "DVIS_DAQ_offline"   # offline mode tracks all frames at once
  BACKBONE:
    NAME: "D2VitAdapterDinoV2"  # DINOv2 pre-trained ViT adapter as backbone
  VIT_ADAPTER:
    FINETUNE: True  # choose to fine tune the adapter
    NAME: 'vitl'
    VIT_WEIGHT: '/home/simone/checkpoints/dinov2_vitl14_pretrain.pth'   # path to pre-trained weights
    FREEZE_VIT: True  # choose to freeze the main ViT backbone (trains only the adapter)
    FINETUNE_INDEXES: [2, 3]   # Fine-tuning the last two stages (12 blocks) for better adaptation.
  SEM_SEG_HEAD:
    NUM_CLASSES: 5 
  MASK_FORMER:
    TEST:
      TASK: 'vis'  # video instance segmentation task
      WINDOW_INFERENCE: True  # run inference on small frame windows for memory savings
      WINDOW_SIZE: 15  # size of the window for inference (smaller = less memory)
  VIDEO_HEAD:
    NUM_NEW_INS: 10  # maximum number of new instances to consider per frame

DATASETS:
  DATASET_RATIO: [1.0] # Ratio for mixing multiple datasets (1.0 means use all of this dataset)
  DATASET_NEED_MAP: [False]  # whether the dataset needs category mapping (False = no mapping needed)
  DATASET_TYPE: ['video_instance']  # type of dataset (video_instance = video instance segmentation)
  TRAIN: ("ytvis_fishway_train",)  # training dataset
  TEST: ("ytvis_fishway_val",)  # testing dataset

SOLVER:
  IMS_PER_BATCH: 1  # Images per batch... Adjust based on your GPU memory
  BASE_LR: 0.0001  # base learning rate... keep low for fine tuning
  STEPS: (4400, 5520)     # Iterations at which the learning rate is decreased
  MAX_ITER: 6900     # Maximum number of training iterations
  WARMUP_ITERS: 138   # Number of iterations for learning rate warmup
  CHECKPOINT_PERIOD: 276  # How often (in iterations) to save checkpoints
  BACKBONE_MULTIPLIER: 0.1  # Multiplier for the learning rate of the backbone
  # Memory optimization settings
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "norm"
    CLIP_VALUE: 0.1
    NORM_TYPE: 2.0

INPUT:
  # Moderate size variations - preserve motion context
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640)  # Reduced range to maintain motion visibility
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"  # Sample different sizes per clip
  MAX_SIZE_TRAIN: 768  # Keep max size for resolution
  
  # Testing sizes
  MIN_SIZE_TEST: 224 # shorter side of of images is resized to this value during testing
  MAX_SIZE_TEST: 320 # longer side is capped at this value during testing
  
  # Frame sampling - optimized for motion capture
  SAMPLING_FRAME_NUM: 15 # number of frames to sample from each video clip during training
  SAMPLING_FRAME_RANGE: 7 # how many frames to sample before and after the reference frame
  SAMPLING_FRAME_STRIDE: 2 # Reduced stride to capture more motion detail
  
  # MOTION-PRESERVING AUGMENTATIONS ONLY
  # REMOVED: REVERSE_AGU - This would destroy temporal motion patterns
  # KEPT: RANDOM_FLIP - Direction doesn't matter as long as temporal order is preserved
  # REMOVED: ROTATION - This would distort motion trajectories
  RANDOM_FLIP: "flip_by_clip"  # Flip all frames in a clip the same way
  
  FORMAT: "RGB"  # Color format of the images
  
  # Conservative crop that preserves motion context
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (512, 640)  # Larger crop to preserve motion context
    # Ensure crop doesn't cut off fish motion paths
  
  # Conservative Large Scale Jittering
  LSJ_AUG:
    ENABLED: True
    IMAGE_SIZE: 768
    MIN_SCALE: 0.5  # Increased minimum scale to preserve motion visibility
    MAX_SCALE: 1.5  # Reduced maximum scale to avoid excessive scaling
  
  # Supported augmentations (motion-preserving)
  AUGMENTATIONS: ['brightness', 'contrast', 'saturation']  # Motion-preserving color augmentations
  # Note: 'rotation' removed as it would distort motion trajectories

DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True # whether to filter out images with no annotations

OUTPUT_DIR: '/store/simone/dvis-model-outputs/trained_models/motion_preserving_0.0001_15f'

#TEST:
#  EVAL_PERIOD: 50  # How often to run evaluation 